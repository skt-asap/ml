{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n",
      "\n",
      "클러스터 0 처리 중...\n",
      "[LightGBM] [Info] Number of positive: 88170, number of negative: 613935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 154\n",
      "[LightGBM] [Info] Number of data points in the train set: 702105, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.125580 -> initscore=-1.940622\n",
      "[LightGBM] [Info] Start training from score -1.940622\n",
      "[LightGBM] [Info] Number of positive: 229080, number of negative: 473025\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 154\n",
      "[LightGBM] [Info] Number of data points in the train set: 702105, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.326276 -> initscore=-0.725077\n",
      "[LightGBM] [Info] Start training from score -0.725077\n",
      "[LightGBM] [Info] Number of positive: 177416, number of negative: 524689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 154\n",
      "[LightGBM] [Info] Number of data points in the train set: 702105, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.252692 -> initscore=-1.084308\n",
      "[LightGBM] [Info] Start training from score -1.084308\n",
      "학습 시간: 3.33 초\n",
      "클러스터 0 정확도: 0.9192\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cell_2100       0.97      0.64      0.77     22109\n",
      "cell_2600_10       0.95      0.90      0.93     57537\n",
      "cell_2600_20       0.96      0.93      0.94     44970\n",
      "\n",
      "   micro avg       0.96      0.86      0.91    124616\n",
      "   macro avg       0.96      0.82      0.88    124616\n",
      "weighted avg       0.96      0.86      0.90    124616\n",
      " samples avg       0.52      0.51      0.51    124616\n",
      "\n",
      "\n",
      "클러스터 2 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 143872, number of negative: 944086\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 214\n",
      "[LightGBM] [Info] Number of data points in the train set: 1087958, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.132240 -> initscore=-1.881293\n",
      "[LightGBM] [Info] Start training from score -1.881293\n",
      "[LightGBM] [Info] Number of positive: 308788, number of negative: 779170\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 214\n",
      "[LightGBM] [Info] Number of data points in the train set: 1087958, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.283823 -> initscore=-0.925574\n",
      "[LightGBM] [Info] Start training from score -0.925574\n",
      "[LightGBM] [Info] Number of positive: 164763, number of negative: 923195\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 214\n",
      "[LightGBM] [Info] Number of data points in the train set: 1087958, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151442 -> initscore=-1.723332\n",
      "[LightGBM] [Info] Start training from score -1.723332\n",
      "학습 시간: 4.23 초\n",
      "클러스터 2 정확도: 0.9171\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cell_2100       0.98      0.71      0.82     36153\n",
      "cell_2600_10       0.95      0.89      0.92     77580\n",
      "cell_2600_20       0.98      0.85      0.91     41208\n",
      "\n",
      "   micro avg       0.96      0.83      0.89    154941\n",
      "   macro avg       0.97      0.81      0.88    154941\n",
      "weighted avg       0.96      0.83      0.89    154941\n",
      " samples avg       0.40      0.39      0.39    154941\n",
      "\n",
      "\n",
      "클러스터 3 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 45719, number of negative: 392309\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 114\n",
      "[LightGBM] [Info] Number of data points in the train set: 438028, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.104375 -> initscore=-2.149536\n",
      "[LightGBM] [Info] Start training from score -2.149536\n",
      "[LightGBM] [Info] Number of positive: 92944, number of negative: 345084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 114\n",
      "[LightGBM] [Info] Number of data points in the train set: 438028, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212187 -> initscore=-1.311791\n",
      "[LightGBM] [Info] Start training from score -1.311791\n",
      "[LightGBM] [Info] Number of positive: 74407, number of negative: 363621\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 114\n",
      "[LightGBM] [Info] Number of data points in the train set: 438028, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.169868 -> initscore=-1.586562\n",
      "[LightGBM] [Info] Start training from score -1.586562\n",
      "학습 시간: 1.80 초\n",
      "클러스터 3 정확도: 0.9288\n",
      "\n",
      "분류 보고서:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cell_2100       1.00      0.70      0.83     11455\n",
      "cell_2600_10       0.95      0.84      0.89     23153\n",
      "cell_2600_20       0.99      0.92      0.95     18425\n",
      "\n",
      "   micro avg       0.97      0.84      0.90     53033\n",
      "   macro avg       0.98      0.82      0.89     53033\n",
      "weighted avg       0.97      0.84      0.90     53033\n",
      " samples avg       0.35      0.34      0.34     53033\n",
      "\n",
      "\n",
      "클러스터 4 처리 중...\n",
      "[LightGBM] [Info] Number of positive: 71698, number of negative: 559413\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 631111, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113606 -> initscore=-2.054425\n",
      "[LightGBM] [Info] Start training from score -2.054425\n",
      "[LightGBM] [Info] Number of positive: 233926, number of negative: 397185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 631111, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370657 -> initscore=-0.529397\n",
      "[LightGBM] [Info] Start training from score -0.529397\n",
      "[LightGBM] [Info] Number of positive: 120490, number of negative: 510621\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 143\n",
      "[LightGBM] [Info] Number of data points in the train set: 631111, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190917 -> initscore=-1.444061\n",
      "[LightGBM] [Info] Start training from score -1.444061\n",
      "학습 시간: 2.69 초\n",
      "클러스터 4 정확도: 0.9007\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cell_2100       0.99      0.53      0.69     17800\n",
      "cell_2600_10       0.94      0.90      0.92     58534\n",
      "cell_2600_20       0.96      0.86      0.91     29887\n",
      "\n",
      "   micro avg       0.95      0.83      0.89    106221\n",
      "   macro avg       0.96      0.77      0.84    106221\n",
      "weighted avg       0.95      0.83      0.88    106221\n",
      " samples avg       0.46      0.45      0.45    106221\n",
      "\n",
      "\n",
      "클러스터 6 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 60730, number of negative: 467315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 128\n",
      "[LightGBM] [Info] Number of data points in the train set: 528045, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115009 -> initscore=-2.040566\n",
      "[LightGBM] [Info] Start training from score -2.040566\n",
      "[LightGBM] [Info] Number of positive: 269787, number of negative: 258258\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 128\n",
      "[LightGBM] [Info] Number of data points in the train set: 528045, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.510917 -> initscore=0.043674\n",
      "[LightGBM] [Info] Start training from score 0.043674\n",
      "[LightGBM] [Info] Number of positive: 75070, number of negative: 452975\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 128\n",
      "[LightGBM] [Info] Number of data points in the train set: 528045, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142166 -> initscore=-1.797416\n",
      "[LightGBM] [Info] Start training from score -1.797416\n",
      "학습 시간: 2.43 초\n",
      "클러스터 6 정확도: 0.8457\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cell_2100       0.94      0.21      0.35     15137\n",
      "cell_2600_10       0.90      0.93      0.92     67547\n",
      "cell_2600_20       0.92      0.68      0.78     18543\n",
      "\n",
      "   micro avg       0.91      0.78      0.84    101227\n",
      "   macro avg       0.92      0.61      0.68    101227\n",
      "weighted avg       0.91      0.78      0.81    101227\n",
      " samples avg       0.56      0.55      0.56    101227\n",
      "\n",
      "\n",
      "클러스터 7 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 170690, number of negative: 601970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 165\n",
      "[LightGBM] [Info] Number of data points in the train set: 772660, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220912 -> initscore=-1.260359\n",
      "[LightGBM] [Info] Start training from score -1.260359\n",
      "[LightGBM] [Info] Number of positive: 389966, number of negative: 382694\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 165\n",
      "[LightGBM] [Info] Number of data points in the train set: 772660, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504706 -> initscore=0.018824\n",
      "[LightGBM] [Info] Start training from score 0.018824\n",
      "[LightGBM] [Info] Number of positive: 273571, number of negative: 499089\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 165\n",
      "[LightGBM] [Info] Number of data points in the train set: 772660, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.354064 -> initscore=-0.601223\n",
      "[LightGBM] [Info] Start training from score -0.601223\n",
      "학습 시간: 3.91 초\n",
      "클러스터 7 정확도: 0.7986\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cell_2100       0.93      0.40      0.56     42875\n",
      "cell_2600_10       0.86      0.92      0.89     97479\n",
      "cell_2600_20       0.89      0.86      0.88     68660\n",
      "\n",
      "   micro avg       0.88      0.79      0.83    209014\n",
      "   macro avg       0.89      0.73      0.77    209014\n",
      "weighted avg       0.88      0.79      0.82    209014\n",
      " samples avg       0.71      0.68      0.69    209014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 정확도: 0.8851\n",
      "\n",
      "전체 분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cell_2100       0.97      0.53      0.69    145529\n",
      "cell_2600_10       0.91      0.91      0.91    381830\n",
      "cell_2600_20       0.94      0.86      0.90    221693\n",
      "\n",
      "   micro avg       0.93      0.82      0.87    749052\n",
      "   macro avg       0.94      0.77      0.83    749052\n",
      "weighted avg       0.93      0.82      0.86    749052\n",
      " samples avg       0.50      0.49      0.49    749052\n",
      "\n",
      "클러스터 0 모델이 저장되었습니다.\n",
      "클러스터 2 모델이 저장되었습니다.\n",
      "클러스터 3 모델이 저장되었습니다.\n",
      "클러스터 4 모델이 저장되었습니다.\n",
      "클러스터 6 모델이 저장되었습니다.\n",
      "클러스터 7 모델이 저장되었습니다.\n",
      "\n",
      "모든 처리가 완료되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import time\n",
    "import joblib\n",
    "import io\n",
    "\n",
    "# 결과를 저장할 StringIO 객체 생성\n",
    "report_buffer = io.StringIO()\n",
    "\n",
    "def log_result(message):\n",
    "    print(message)\n",
    "    print(message, file=report_buffer)\n",
    "\n",
    "# 데이터 로드\n",
    "log_result(\"데이터 로딩 중...\")\n",
    "data = pd.read_csv('labeled_data.csv')\n",
    "\n",
    "# timestamp를 datetime으로 변환하고 추가 특성 생성\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "data['hour'] = data['timestamp'].dt.hour\n",
    "data['minute'] = data['timestamp'].dt.minute\n",
    "data['quarter_hour'] = data['minute'] // 15\n",
    "data['is_weekend'] = data['day_of_week'].isin([5, 6]).astype(int)\n",
    "data['is_rush_hour'] = data['hour'].isin([7, 8, 9, 17, 18, 19]).astype(int)\n",
    "\n",
    "# 특성과 타겟 정의\n",
    "features = ['hour', 'Holiday', 'enbid_pci', 'day_of_week', 'quarter_hour',\n",
    "            'is_weekend', 'is_rush_hour']\n",
    "X = data[features]\n",
    "y = data[['cell_2100', 'cell_2600_10', 'cell_2600_20']]\n",
    "\n",
    "# 클러스터별로 모델 학습 및 예측\n",
    "clusters = [0, 2, 3, 4, 6, 7]  # 주어진 클러스터 목록\n",
    "models = {}\n",
    "predictions = pd.DataFrame()\n",
    "overall_y_true = pd.DataFrame()\n",
    "overall_y_pred = pd.DataFrame()\n",
    "\n",
    "for cluster in clusters:\n",
    "    log_result(f\"\\n클러스터 {cluster} 처리 중...\")\n",
    "    # 클러스터별 데이터 분할\n",
    "    cluster_mask = data['cluster'] == cluster\n",
    "    X_cluster = X[cluster_mask]\n",
    "    y_cluster = y[cluster_mask]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cluster, y_cluster, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 범주형 변수 처리\n",
    "    for col in ['hour', 'Holiday', 'enbid_pci', 'day_of_week', 'quarter_hour']:\n",
    "        X_train[col] = X_train[col].astype('category')\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "    # 모델 정의 및 학습\n",
    "    lgb_model = MultiOutputClassifier(LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        random_state=42\n",
    "    ))\n",
    "    start_time = time.time()\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    log_result(f\"학습 시간: {train_time:.2f} 초\")\n",
    "\n",
    "    # 예측\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "    # 성능 평가\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    log_result(f\"클러스터 {cluster} 정확도: {accuracy:.4f}\")\n",
    "    log_result(\"\\n분류 보고서:\")\n",
    "    log_result(classification_report(y_test, y_pred, target_names=['cell_2100', 'cell_2600_10', 'cell_2600_20']))\n",
    "\n",
    "    # 모델 저장\n",
    "    models[cluster] = lgb_model\n",
    "\n",
    "    # 전체 성능 평가를 위한 데이터 저장\n",
    "    overall_y_true = pd.concat([overall_y_true, y_test])\n",
    "    overall_y_pred = pd.concat([overall_y_pred, pd.DataFrame(y_pred, columns=['cell_2100', 'cell_2600_10', 'cell_2600_20'])])\n",
    "\n",
    "# 전체 성능 평가\n",
    "overall_accuracy = accuracy_score(overall_y_true, overall_y_pred)\n",
    "log_result(f\"\\n전체 정확도: {overall_accuracy:.4f}\")\n",
    "log_result(\"\\n전체 분류 보고서:\")\n",
    "log_result(classification_report(overall_y_true, overall_y_pred, target_names=['cell_2100', 'cell_2600_10', 'cell_2600_20']))\n",
    "\n",
    "# 모델 저장\n",
    "for cluster, model in models.items():\n",
    "    joblib.dump(model, f'cluster_{cluster}_model.joblib')\n",
    "    log_result(f\"클러스터 {cluster} 모델이 저장되었습니다.\")\n",
    "\n",
    "log_result(\"\\n모든 처리가 완료되었습니다.\")\n",
    "\n",
    "# 결과 보고서를 파일로 저장\n",
    "with open('classification_report.txt', 'w', encoding='utf-8') as report_file:\n",
    "    report_file.write(report_buffer.getvalue())\n",
    "\n",
    "log_result(\"결과 보고서가 'classification_report.txt' 파일로 저장되었습니다.\")\n",
    "\n",
    "# StringIO 버퍼 닫기\n",
    "report_buffer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
